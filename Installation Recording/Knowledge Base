sudo apt update && sudo apt upgrade -y
sudo apt install python3 python3-pip git libgl1 -y
#更新系统并安装基础工具

python3 -m venv rag-env
source rag-env/bin/activate
pip install --upgrade pip
#创建 Python 环境

pip install fastapi uvicorn python-multipart
pip install langchain sentence-transformers chromadb
pip install unstructured[all] pdfminer.six python-docx "unstructured[pdf]"
#安装核心依赖
#fastapi/uvicorn：用于部署接口服务，供 A机 远程访问
#langchain：文档处理框架
#sentence-transformers：用于中英文兼容的嵌入模型（如multi-qa-MiniLM）
#chromadb：作为本地轻量级向量数据库
#unstructured、pdfminer.six、python-docx：用于解析PDF、Word文档

mkdir rag-server
cd rag-server
mkdir docs
#初始化项目目录结构
#docs/：放置你的 PDF、Word 等知识库文档

vim build_vector_db.py
#######生成向量数据库#########
import os
from glob import glob
from langchain_community.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import SentenceTransformerEmbeddings

# 确保目录存在
os.makedirs("docs", exist_ok=True)
os.makedirs("chroma_db", exist_ok=True)

# 使用中英混合嵌入模型
embedding_model = SentenceTransformerEmbeddings(model_name="shibing624/text2vec-base-multilingual")

# 加载或初始化向量数据库
vector_db = Chroma(persist_directory="chroma_db", embedding_function=embedding_model)

# 加载所有文档
files = glob("docs/*")
if not files:
    print("❌ No documents found in /docs folder.")
    exit(1)

for file_path in files:
    try:
        print(f"📄 Processing: {file_path}")
        loader = UnstructuredFileLoader(file_path)
        docs = loader.load()

        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        chunks = splitter.split_documents(docs)

        vector_db.add_documents(chunks)
    except Exception as e:
        print(f"⚠️ Error processing {file_path}: {str(e)}")

print("✅ Vector DB built and saved to chroma_db/")
################
python3 build_vector_db.py
#每次在docs目录下上传或删除了新的文档后，可跑这个命令重新构建向量数据库

vim main.py
#######运行 FastAPI 服务#########
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import SentenceTransformerEmbeddings

class QueryRequest(BaseModel):
    q: str

app = FastAPI()

# 加载向量库
embedding_model = SentenceTransformerEmbeddings(model_name="shibing624/text2vec-base-multilingual")
vector_db = Chroma(persist_directory="chroma_db", embedding_function=embedding_model)

@app.post("/query")
async def query_knowledge(request: QueryRequest):
    # 仅返回检索结果，不调用LLM
    docs = vector_db.similarity_search(request.q, k=3)
    return {
        "query": request.q,
        "results": [
            {"content": doc.page_content, "source": doc.metadata.get("source", "")}
            for doc in docs
        ]
    }
################

uvicorn main:app --host 0.0.0.0 --port 8000
#启动服务
