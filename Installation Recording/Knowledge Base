sudo apt update && sudo apt upgrade -y
sudo apt install python3 python3-pip git libgl1 -y
#æ›´æ–°ç³»ç»Ÿå¹¶å®‰è£…åŸºç¡€å·¥å…·

python3 -m venv rag-env
source rag-env/bin/activate
pip install --upgrade pip
#åˆ›å»º Python ç¯å¢ƒ

pip install fastapi uvicorn python-multipart
pip install langchain sentence-transformers chromadb
pip install unstructured[all] pdfminer.six python-docx "unstructured[pdf]"
#å®‰è£…æ ¸å¿ƒä¾èµ–
#fastapi/uvicornï¼šç”¨äºéƒ¨ç½²æ¥å£æœåŠ¡ï¼Œä¾› Aæœº è¿œç¨‹è®¿é—®
#langchainï¼šæ–‡æ¡£å¤„ç†æ¡†æ¶
#sentence-transformersï¼šç”¨äºä¸­è‹±æ–‡å…¼å®¹çš„åµŒå…¥æ¨¡å‹ï¼ˆå¦‚multi-qa-MiniLMï¼‰
#chromadbï¼šä½œä¸ºæœ¬åœ°è½»é‡çº§å‘é‡æ•°æ®åº“
#unstructuredã€pdfminer.sixã€python-docxï¼šç”¨äºè§£æPDFã€Wordæ–‡æ¡£

mkdir rag-server
cd rag-server
mkdir docs
#åˆå§‹åŒ–é¡¹ç›®ç›®å½•ç»“æ„
#docs/ï¼šæ”¾ç½®ä½ çš„ PDFã€Word ç­‰çŸ¥è¯†åº“æ–‡æ¡£

vim build_vector_db.py
#######ç”Ÿæˆå‘é‡æ•°æ®åº“#########
import os
from glob import glob
from langchain_community.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import SentenceTransformerEmbeddings

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs("docs", exist_ok=True)
os.makedirs("chroma_db", exist_ok=True)

# ä½¿ç”¨ä¸­è‹±æ··åˆåµŒå…¥æ¨¡å‹
embedding_model = SentenceTransformerEmbeddings(model_name="shibing624/text2vec-base-multilingual")

# åŠ è½½æˆ–åˆå§‹åŒ–å‘é‡æ•°æ®åº“
vector_db = Chroma(persist_directory="chroma_db", embedding_function=embedding_model)

# åŠ è½½æ‰€æœ‰æ–‡æ¡£
files = glob("docs/*")
if not files:
    print("âŒ No documents found in /docs folder.")
    exit(1)

for file_path in files:
    try:
        print(f"ğŸ“„ Processing: {file_path}")
        loader = UnstructuredFileLoader(file_path)
        docs = loader.load()

        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        chunks = splitter.split_documents(docs)

        vector_db.add_documents(chunks)
    except Exception as e:
        print(f"âš ï¸ Error processing {file_path}: {str(e)}")

print("âœ… Vector DB built and saved to chroma_db/")
################
python3 build_vector_db.py
#æ¯æ¬¡åœ¨docsç›®å½•ä¸‹ä¸Šä¼ æˆ–åˆ é™¤äº†æ–°çš„æ–‡æ¡£åï¼Œå¯è·‘è¿™ä¸ªå‘½ä»¤é‡æ–°æ„å»ºå‘é‡æ•°æ®åº“

vim main.py
#######è¿è¡Œ FastAPI æœåŠ¡#########
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import SentenceTransformerEmbeddings

class QueryRequest(BaseModel):
    q: str

app = FastAPI()

# åŠ è½½å‘é‡åº“
embedding_model = SentenceTransformerEmbeddings(model_name="shibing624/text2vec-base-multilingual")
vector_db = Chroma(persist_directory="chroma_db", embedding_function=embedding_model)

@app.post("/query")
async def query_knowledge(request: QueryRequest):
    # ä»…è¿”å›æ£€ç´¢ç»“æœï¼Œä¸è°ƒç”¨LLM
    docs = vector_db.similarity_search(request.q, k=3)
    return {
        "query": request.q,
        "results": [
            {"content": doc.page_content, "source": doc.metadata.get("source", "")}
            for doc in docs
        ]
    }
################

uvicorn main:app --host 0.0.0.0 --port 8000
#å¯åŠ¨æœåŠ¡
